{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"OpenShift Quickstart","text":"<p>Welcome to the OpenShift Quickstart workshop!  This workshop is designed to provide you with a seamless development experience, whether you choose to work locally on your laptop or leverage the OpenShift DevSpaces Cloud IDE.  Both environments are equipped to help you efficiently set up and manage your development projects with ease. Follow the instructions below to get started with your preferred setup.</p>"},{"location":"#laptop","title":"Laptop","text":""},{"location":"#prerequisite-install-podman-desktop","title":"Prerequisite: Install Podman Desktop","text":"<p>Before proceeding, make sure you have Podman Desktop installed on your laptop.  You can download and install it from the official website: (https://podman-desktop.io/)[Podman Desktop].</p> <p></p>"},{"location":"#creating-a-podman-machine","title":"Creating a Podman Machine","text":"<p>To run containers locally using Podman, you need to set up a Podman machine. This is a virtual machine that runs a Podman service, allowing you to manage containers as you would on a remote server.</p>"},{"location":"#steps-to-create-a-podman-machine","title":"Steps to Create a Podman Machine","text":"<ol> <li> <p>Open your terminal: Ensure you have access to a terminal on your local machine.</p> </li> <li> <p>Create a Podman machine: Use the following command to create a new Podman machine. This will set up a virtual environment for running containers.    <pre><code>podman machine init\n</code></pre></p> </li> <li> <p>Start the Podman machine: Once the machine is initialized, start it using the command below. This will boot up the virtual machine and prepare it for container operations.    <pre><code>podman machine start\n</code></pre></p> </li> <li> <p>Verify the machine status: Check the status of your Podman machine to ensure it is running correctly.    <pre><code>podman machine list\n</code></pre></p> </li> <li> <p>Connect to the Podman machine: You can now use Podman commands to manage containers on your machine. For example, to check the version of Podman running, use:    <pre><code>podman version\n</code></pre></p> </li> </ol>"},{"location":"#git-clone","title":"Git Clone","text":"<ol> <li>Open your terminal.</li> <li>Choose your root workspace project:<ul> <li>Decide on the directory where you want your root workspace to reside. This will be the main directory for your project files and configurations.</li> </ul> </li> <li>Navigate to the directory where you want to clone the project (e.g. <code>/projects</code>).</li> <li> <p>Run the following command to clone the Git repository:    <pre><code>cd /projects/\ngit clone https://github.com/openlab-red/openshift-quickstart.git\ngit clone https://github.com/openlab-red/openshift-quickstart-manifest.git\n</code></pre></p> </li> <li> <p>Open Visual Studio Code or your favourite IDEs:    <pre><code>code .\n</code></pre></p> </li> <li> <p>Log into your OpenShift cluster at OpenShift Console.    </p> </li> <li> <p>Navigate to the DevSpaces dashboard.    </p> </li> </ol> <p>Note: Even if working locally, having a DevSpaces namespace allows to have all necessary configuratin in place for the tutorial</p>"},{"location":"#necessary-tools-and-how-to-get-them","title":"Necessary Tools and How to Get Them","text":"<p>To effectively work with OpenShift and the associated projects, ensure you have the following tools installed on your local machine:</p>"},{"location":"#openshift-client-oc","title":"OpenShift Client (oc)","text":"<p>The OpenShift CLI (<code>oc</code>) is a command-line tool that helps you manage OpenShift applications and the OpenShift container platform itself.</p> <ul> <li>Installation: You can download the <code>oc</code> client directly from the OpenShift Console. Navigate to the question mark icon and select \"Command Line Tools\" to find the appropriate version for your operating system.</li> </ul>"},{"location":"#helm-client","title":"Helm Client","text":"<p>Helm is a package manager for Kubernetes that allows you to define, install, and upgrade even the most complex Kubernetes applications.</p> <ul> <li>Installation: Similar to the <code>oc</code> client, Helm can also be downloaded from the OpenShift Console. Go to the question mark icon and choose \"Command Line Tools\" to access the Helm download options.</li> </ul>"},{"location":"#kustomize","title":"Kustomize","text":"<p>Kustomize is a tool for customizing Kubernetes configurations.</p> <ul> <li>Installation: You can install Kustomize by following the instructions on the Kustomize Installation page.</li> </ul>"},{"location":"#language-specific-tools","title":"Language-Specific Tools","text":""},{"location":"#nodejs","title":"Node.js","text":"<p>Node.js is a JavaScript runtime built on Chrome's V8 JavaScript engine, essential for running JavaScript applications.</p> <ul> <li>Installation: Download and install Node.js from the official Node.js website.</li> </ul>"},{"location":"#java","title":"Java","text":"<p>Java is a high-level, class-based, object-oriented programming language that is widely used for building enterprise-scale applications.</p> <ul> <li>Installation: You can download the latest version of OpenJDK from the OpenJDK Downloads page.</li> </ul>"},{"location":"#golang","title":"Golang","text":"<p>Golang, or Go, is an open-source programming language that makes it easy to build simple, reliable, and efficient software. - Installation: Visit the Go Downloads page to download and install Go on your machine.</p>"},{"location":"#devspaces","title":"DevSpaces","text":""},{"location":"#using-devspaces-with-devfile","title":"Using DevSpaces with Devfile","text":"<p>OpenShift DevSpaces provides a cloud-based development environment using the configuration specified in the <code>devfile.yaml</code>. </p> <p>Follow these steps to get started:</p> <ol> <li> <p>Log into your OpenShift cluster at OpenShift Console.    </p> </li> <li> <p>Navigate to the DevSpaces dashboard.    </p> </li> <li> <p>Create a new workspace by importing this repository URL:    <pre><code>https://github.com/openlab-red/openshift-quickstart.git\n</code></pre>     DevSpaces will automatically detect and use the <code>devfile.yaml</code> at the root of the project.</p> </li> <li> <p>The devfile configures:</p> <ul> <li>A developer container with ZSH shell</li> <li>Default workspace pointing to the project's VS Code workspace</li> <li>Required environment variables and configurations</li> </ul> </li> <li> <p>Once the workspace starts:</p> <ul> <li>You'll have a fully configured development environment</li> <li>All necessary tools and dependencies will be pre-installed    </li> </ul> </li> </ol> <p>Note: The devfile inherits configurations from a parent devfile that contains base developer tooling and settings.</p>"},{"location":"setup/","title":"Workshop Cluster Setup Guide","text":"<p>This guide will walk you through the process of setting up the workshop cluster using Kustomize and OpenShift CLI (oc).</p>"},{"location":"setup/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following tools installed: - OpenShift CLI (<code>oc</code>) - Kustomize - Access to an OpenShift cluster with sufficient permissions - OpenShift version 4.18.x or higher</p>"},{"location":"setup/#setup-steps","title":"Setup Steps","text":""},{"location":"setup/#1-deploy-base-cluster-configuration","title":"1. Deploy Base Cluster Configuration","text":"<p>First, deploy the base cluster configuration using Kustomize:</p> <pre><code>kustomize build cluster/base | oc apply -f -\n</code></pre> <p>This command will: - Build the Kubernetes manifests from the base configuration - Apply them directly to your OpenShift cluster</p>"},{"location":"setup/#2-deploy-tekton-tasks","title":"2. Deploy Tekton Tasks","text":"<p>Next, deploy the required Tekton tasks for the workshop:</p> <pre><code>kustomize build cluster/tekton-tasks/base | oc apply -f -\n</code></pre> <p>This step sets up the CI/CD pipeline components needed for the workshop environment.</p>"},{"location":"setup/#3-deploy-devspaces-configuration","title":"3. Deploy DevSpaces Configuration","text":"<p>Finally, deploy the DevSpaces configuration with nested container support:</p> <pre><code>kustomize build devspaces/overlays/nested-container | oc apply -f -\n</code></pre>"},{"location":"setup/#verification","title":"Verification","text":"<p>After running all commands, verify your setup by: 1. Checking that all resources are in the <code>Running</code> or <code>Completed</code> state 2. Ensuring no errors are present in the cluster events 3. Verifying that DevSpaces is accessible</p>"},{"location":"setup/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter any issues: 1. Check the logs of the deployed pods 2. Verify your cluster permissions 3. Ensure all prerequisites are properly installed 4. Check the OpenShift cluster events for any error messages</p>"},{"location":"setup/#additional-notes","title":"Additional Notes","text":"<ul> <li>Make sure to run these commands in the order specified</li> <li>Wait for each step to complete before proceeding to the next</li> <li>Monitor the cluster events during deployment for any potential issues</li> </ul>"},{"location":"tutorials/gitops/argocd/","title":"Argo CD Setup Tutorial","text":"<p>This tutorial guides you through setting up Argo CD on OpenShift and deploying applications using Argo CD Application manifests. We'll cover installing Argo CD, configuring it, and deploying example applications (<code>go-app</code>, <code>angular-app</code>, and <code>java-app</code>).</p> <p>Note: All YAML files referenced in this tutorial are located under the <code>openshift-quickstart/gitops/argocd</code> directory. Ensure you navigate to this directory before executing commands.</p>"},{"location":"tutorials/gitops/argocd/#1-install-argo-cd-on-openshift","title":"1. Install Argo CD on OpenShift","text":"<p>First, we need to install Argo CD using the provided YAML manifest (<code>argocd.yaml</code>). This manifest configures Argo CD with OpenShift OAuth integration, resource limits, and exclusions.</p>"},{"location":"tutorials/gitops/argocd/#navigate-to-the-argo-cd-directory","title":"Navigate to the Argo CD Directory","text":"<pre><code>cd openshift-quickstart/gitops/argocd\n</code></pre>"},{"location":"tutorials/gitops/argocd/#adjust-namespace-in-argo-cd-manifest","title":"Adjust Namespace in Argo CD Manifest","text":"<p>Before applying the manifest, edit the <code>argocd.yaml</code> file to replace the default namespace (<code>devspaces-admin</code>) with your specific user namespace (<code>user1</code>, <code>devspaces-user1</code>, etc.):</p> <pre><code># argocd.yaml\nmetadata:\n  name: argocd\n  namespace: &lt;your-user-namespace&gt; # Replace with your namespace\n</code></pre>"},{"location":"tutorials/gitops/argocd/#apply-the-argo-cd-manifest","title":"Apply the Argo CD Manifest","text":"<p>Deploy Argo CD using the following command:</p> <pre><code>oc apply -f argocd.yaml\n</code></pre> <p>This command will:</p> <ul> <li>Deploy Argo CD in your specified user namespace.</li> <li>Enable OpenShift OAuth integration for Single Sign-On (SSO).</li> <li>Configure resource limits and requests for Argo CD components.</li> <li>Exclude Tekton resources (<code>TaskRun</code>, <code>PipelineRun</code>) from Argo CD management.</li> </ul>"},{"location":"tutorials/gitops/argocd/#2-access-the-argo-cd-ui","title":"2. Access the Argo CD UI","text":"<p>After installation, access the Argo CD UI through the OpenShift route:</p> <ol> <li>Log in to your OpenShift Console.</li> <li>Navigate to Networking \u2192 Routes in your specific user namespace.</li> <li>Click on the Argo CD route URL to open the Argo CD UI.</li> <li>Log in using your OpenShift credentials (OAuth integration is enabled).</li> </ol>"},{"location":"tutorials/gitops/argocd/#3-deploy-applications-using-argo-cd","title":"3. Deploy Applications Using Argo CD","text":"<p>We will deploy three example applications (<code>go-app</code>, <code>angular-app</code>, and <code>java-app</code>) using Argo CD Application manifests.</p>"},{"location":"tutorials/gitops/argocd/#adjust-namespace-in-application-manifests","title":"Adjust Namespace in Application Manifests","text":"<p>Before deploying, edit each application manifest (<code>go-app.yaml</code>, <code>angular.yaml</code>, <code>java-app.yaml</code>) to replace the default namespace (<code>devspaces-admin</code>) with your specific user namespace:</p> <pre><code># Example adjustment in go-app.yaml, angular.yaml, java-app.yaml\nspec:\n  destination:\n    namespace: &lt;your-user-namespace&gt; # Replace with your namespace\n    server: 'https://kubernetes.default.svc'\n</code></pre>"},{"location":"tutorials/gitops/argocd/#deploying-the-applications","title":"Deploying the Applications","text":"<p>Deploy each application by applying its respective YAML manifest:</p>"},{"location":"tutorials/gitops/argocd/#deploy-go-application-go-app","title":"Deploy Go Application (<code>go-app</code>):","text":"<pre><code>oc apply -f application/go-app.yaml\n</code></pre>"},{"location":"tutorials/gitops/argocd/#deploy-angular-application-angular-app","title":"Deploy Angular Application (<code>angular-app</code>):","text":"<pre><code>oc apply -f application/angular.yaml\n</code></pre>"},{"location":"tutorials/gitops/argocd/#deploy-java-application-java-app","title":"Deploy Java Application (<code>java-app</code>):","text":"<pre><code>oc apply -f application/java-app.yaml\n</code></pre>"},{"location":"tutorials/gitops/argocd/#4-synchronize-applications-in-argo-cd-ui","title":"4. Synchronize Applications in Argo CD UI","text":"<p>After applying the manifests, synchronize the applications through the Argo CD UI:</p> <ol> <li>Open the Argo CD UI.</li> <li>Navigate to the Applications section.</li> <li>You should see the newly created applications (<code>go-app</code>, <code>angular-app</code>, <code>java-app</code>) listed.</li> <li>Click on each application and then click Sync to deploy the application resources to your cluster.</li> </ol>"},{"location":"tutorials/gitops/argocd/#5-verify-application-deployment","title":"5. Verify Application Deployment","text":"<p>Verify that your applications are successfully deployed:</p> <ul> <li>Navigate to the OpenShift Console.</li> <li>Go to Workloads \u2192 Pods in your specific user namespace.</li> <li>Confirm that pods for each application (<code>go-app</code>, <code>angular-app</code>, <code>java-app</code>) are running and healthy.</li> </ul>"},{"location":"tutorials/gitops/pipeline/","title":"Pipeline Setup","text":"<p>This tutorial will guide you through the process of setting up and executing a pipeline using the provided Helm chart. We will cover creating a pipeline and PVC, launching a PipelineRun, and setting up event listeners and triggers.</p> <p>The code examples and instructions in this tutorial are located under <code>openshift-quickstart</code> project in the <code>tutorials/gitops/pipeline</code> directory.  Ensure you are in this directory before executing the commands. </p> <ol> <li> <p>Navigate to the Tutorial Directory     <pre><code>cd openshift-quickstart/tutorials/gitops/pipeline\n</code></pre></p> </li> <li> <p>Or open a New Terminal</p> </li> </ol>"},{"location":"tutorials/gitops/pipeline/#prerequisites","title":"Prerequisites","text":"<p>Before installing the pipeline, you need to set up registry credentials to allow pushing images to your container registry.</p> <ol> <li> <p>Link the secret to the pipeline service account:</p> <pre><code>oc secrets link pipeline registry-credentials --for=pull,mount\n</code></pre> </li> </ol> <p>This configuration allows the pipeline to authenticate with your container registry when pushing built images.</p>"},{"location":"tutorials/gitops/pipeline/#install-the-pipeline-using-helm","title":"Install the Pipeline Using Helm","text":"<p>The provided Helm chart is designed to be generic and reusable, allowing multiple users and pipeline types to utilize the same chart with minimal configuration. This is achieved through parameterization and naming conventions.</p> <p>Conventions Explained:</p> <ul> <li>Release Name:   The Helm release name should reflect the pipeline type you are deploying. Common examples include:</li> <li><code>java</code></li> <li><code>golang</code></li> <li><code>nodejs</code></li> </ul> <p>This naming convention helps distinguish between different pipeline instances clearly and consistently.</p> <ul> <li>Namespace:   The namespace parameter allows multiple users to deploy their pipelines independently without conflicts. Typically, each user has a dedicated namespace, such as:</li> <li><code>devspaces-user1</code></li> </ul> <p>Using separate namespaces ensures isolation and prevents resource conflicts between different users or teams.</p> <ul> <li>Generic Chart Structure:   The Helm chart uses templating to dynamically generate Kubernetes resources based on the provided parameters. This approach allows the same chart to be reused across different pipeline types and namespaces without modification.</li> </ul> <p>Example Installation Command:</p> <p>Replace <code>&lt;pipeline-type&gt;</code> with your chosen pipeline type (<code>java</code>, <code>golang</code>, or <code>nodejs</code>) and <code>&lt;namespace&gt;</code> with your user-specific namespace (<code>user1</code> or <code>devspaces-user1</code>):</p> <pre><code>helm install &lt;pipeline-type&gt; helm/pipeline --namespace &lt;namespace&gt;\n</code></pre> <p>Detailed Example:</p> <p>For instance, if you are deploying a Java pipeline for user <code>user1</code>, your command would look like this:</p> <pre><code>cd  helm/\nhelm install java . -f java/values.yaml --namespace devspaces-user1\n</code></pre>"},{"location":"tutorials/gitops/pipeline/#understanding-pipeline-resources","title":"Understanding Pipeline Resources","text":"<p>When you install the pipeline Helm chart, it creates several Kubernetes resources that work together to form a complete CI/CD pipeline. Let's understand each component and its role.</p> <p></p>"},{"location":"tutorials/gitops/pipeline/#core-pipeline-definition","title":"Core Pipeline Definition","text":"<p>The main pipeline is created with a series of connected tasks that handle your application's build and deployment process:</p> <pre><code># Example pipeline structure\nPipeline\n\u251c\u2500\u2500 fetch-repository     # Clones source code\n\u251c\u2500\u2500 tag                 # Generates build tag\n\u251c\u2500\u2500 build-app          # Language-specific build\n\u251c\u2500\u2500 build-image        # Creates container image\n\u251c\u2500\u2500 publish            # Publishes to registry\n\u251c\u2500\u2500 fetch-manifest     # Gets GitOps manifests\n\u251c\u2500\u2500 update-manifest    # Updates image details\n\u2514\u2500\u2500 update-gitops     # Updates GitOps config\n</code></pre>"},{"location":"tutorials/gitops/pipeline/#language-specific-builds","title":"Language-Specific Builds","text":"<p>The pipeline automatically includes the appropriate build task based on your chosen pipeline type: - For Java: Maven/Gradle build process - For Golang: Go build process - For JavaScript: npm/yarn build process</p>"},{"location":"tutorials/gitops/pipeline/#persistent-storage","title":"Persistent Storage","text":"<p>The pipeline creates two Persistent Volume Claims (PVCs) to maintain data between pipeline runs:</p> <ol> <li> <p>Workspace PVC (<code>&lt;pipeline-name&gt;-ws</code>):</p> <ul> <li>Size: 10Gi</li> <li>Purpose: Stores source code and build artifacts</li> <li>Access Mode: ReadWriteOnce</li> </ul> </li> <li> <p>Resource Workspace PVC (<code>&lt;pipeline-name&gt;-resource-ws</code>):</p> <ul> <li>Size: 10Gi</li> <li>Purpose: Stores GitOps manifests and configurations</li> <li>Access Mode: ReadWriteOnce</li> </ul> </li> </ol>"},{"location":"tutorials/gitops/pipeline/#trigger-system","title":"Trigger System","text":"<p>The pipeline includes an event-driven system to automatically start builds:</p> <ol> <li> <p>Event Listener:</p> <ul> <li>Acts as a webhook endpoint</li> <li>Receives and validates incoming events</li> <li>Routes events to appropriate triggers</li> </ul> </li> <li> <p>Trigger Template:</p> <ul> <li>Defines how to create PipelineRuns</li> <li>Maps incoming event data to pipeline parameters</li> <li>Ensures consistent pipeline execution</li> </ul> </li> </ol>"},{"location":"tutorials/gitops/pipeline/#usage-example","title":"Usage Example","text":"<p>To install the pipeline with these resources:</p> <pre><code># For a Java application\nhelm install java . -f java/values.yaml --namespace devspaces-user1\n\n# For a Golang application\nhelm install golang . golang/values.yaml --namespace devspaces-user1\n\n# For a JavaScript application\nhelm install js-frontend . js/values.yaml --namespace devspaces-user1\nhelm install js-backend . js/values-backend.yaml --namespace devspaces-user1\n</code></pre>"},{"location":"tutorials/gitops/pipeline/#resource-naming","title":"Resource Naming","text":"<p>All resources follow a consistent naming pattern based on your installation parameters: - Resources are prefixed with the pipeline type (java/golang/js) - Resources are created in the specified namespace - Each resource includes appropriate labels for management and organization</p>"},{"location":"tutorials/gitops/pipeline/#pipeline-flow","title":"Pipeline Flow","text":"<ol> <li>When triggered, the pipeline first clones your source code</li> <li>Generates a unique tag for the build</li> <li>Builds your application using language-specific tools</li> <li>Creates and publishes a container image</li> <li>Updates GitOps manifests with new image details</li> <li>Commits changes to your GitOps repository</li> </ol>"},{"location":"tutorials/gitops/pipeline/#launch-the-pipelinerun","title":"Launch the PipelineRun","text":"<p>To execute the pipeline, we need to create a PipelineRun using the OpenShift UI.</p> <ol> <li> <p>Create the PipelineRun:</p> </li> <li> <p>Navigate to the OpenShift Console and log in with your credentials.</p> </li> <li>Go to the \"Pipelines\" section in your project.</li> <li>Click on the target pipeline from the list.</li> <li> <p>Click Actions and \"Start\" button.</p> </li> <li> <p>Select Workspaces:</p> </li> </ol> <p>Before starting the PipelineRun, ensure that you have selected the appropriate workspaces and PVCs. This is crucial for the pipeline to access necessary resources and credentials.</p> <ul> <li>Select Workspaces:<ul> <li>Ensure the following workspaces are selected:</li> <li><code>&lt;pipeline-type&gt;-ws</code></li> <li><code>&lt;pipeline-type&gt;-resource-ws</code></li> <li><code>&lt;pipeline-type&gt;-dockerconfig</code></li> <li><code>&lt;pipeline-type&gt;-git-credentials</code></li> </ul> </li> </ul> <p></p> <ul> <li> <p>Select PVCs:</p> <ul> <li>Ensure the following PVCs are selected:</li> <li><code>&lt;pipeline-type&gt;-ws</code> (replace with actual PVC name)</li> <li><code>&lt;pipeline-type&gt;-resource-ws</code> (replace with actual PVC name)</li> </ul> </li> <li> <p>Link Docker and GitHub Credentials:</p> <ul> <li>Ensure that the Docker and GitHub credentials are linked to the pipeline service account:</li> <li><code>registry-credentials</code> for Docker</li> <li><code>git-credentials</code> for GitHub</li> </ul> </li> </ul> <p>After selecting the workspaces, PVCs, and linking the credentials, proceed to the next step.</p> <ol> <li>Click \"Start\":</li> </ol> <p>Once all selections are made, click the \"Start\" button to initiate the PipelineRun.</p> <ol> <li>Verify the Manifest Update:</li> </ol> <p>After the pipeline completes successfully, verify that the manifest repository has been updated with the new image details:</p> <ul> <li>Check the latest commit in the repository</li> <li>Verify that the image tag has been updated in the relevant deployment manifests</li> <li>The commit message should indicate the pipeline run that triggered the update</li> </ul> <p>This confirms that the pipeline has successfully built and published the new image, and updated the GitOps manifests accordingly.</p>"},{"location":"tutorials/golang/","title":"Golang REST API with PostgreSQL","text":"<p>This tutorial guides you through building and running a simple REST API using Golang and PostgreSQL.</p>"},{"location":"tutorials/golang/#tutorial","title":"Tutorial","text":"<p>The code examples and instructions in this tutorial are located under the <code>openshift-quickstart</code> project in the <code>tutorials/golang</code> directory. Ensure you are in this directory before executing the commands.</p> <ol> <li> <p>Navigate to the Tutorial Directory <pre><code>cd openshift-quickstart/tutorials/golang\n</code></pre></p> </li> <li> <p>Or open a New Terminal</p> </li> </ol>"},{"location":"tutorials/golang/#features","title":"\ud83d\ude80 Features","text":""},{"location":"tutorials/golang/#backend-golang-rest-api","title":"Backend (Golang REST API)","text":"<ul> <li>Provides RESTful endpoints.</li> <li>Secure database interactions using prepared statements (PostgreSQL).</li> <li>Implements API health check (ping functionality).</li> </ul>"},{"location":"tutorials/golang/#initial-setup","title":"\ud83d\udee0\ufe0f Initial Setup","text":""},{"location":"tutorials/golang/#prerequisite-spin-up-postgresql-container-on-laptop","title":"Prerequisite: Spin Up PostgreSQL Container on Laptop","text":"<p>To set up a PostgreSQL container locally, follow these steps:</p> <ol> <li>Run PostgreSQL Container:</li> </ol> <p>Start a new PostgreSQL container with the following command:</p> <pre><code>podman run -d -v $(pwd):/projects -e POSTGRESQL_USER=user -e POSTGRESQL_PASSWORD=pass -e POSTGRESQL_ROOT_PASSWORD=root -e POSTGRESQL_DATABASE=db -p 5432:5432 registry.redhat.io/rhel9/postgresql-16:latest\n</code></pre> <ol> <li>Verify Container is Running:</li> </ol> <p>Check that your PostgreSQL container is running:</p> <pre><code>podman ps\n</code></pre>"},{"location":"tutorials/golang/#database-configuration-first-time-setup","title":"Database Configuration (First-time setup)","text":"<ol> <li> <p>Open Terminal on PostgreSQL container:</p> </li> <li> <p>Access PostgreSQL Container:</p> </li> </ol> <p>To access the running PostgreSQL container, execute the following command, replacing <code>&lt;containerId&gt;</code> with the actual container ID obtained from the <code>podman ps</code> command:</p> <pre><code>podman exec -it &lt;containerId&gt; bash\n</code></pre> <p>This command will open an interactive terminal session inside the PostgreSQL container, allowing you to run database commands directly.</p> <ol> <li>Initialize Database Schema:</li> </ol> <p>Execute the following command in the terminal (password: <code>pass</code>):</p> <pre><code>cd /projects\npsql -d db -U user -W -f tutorials/golang/db/schema.sql\n</code></pre> <p>Expected Output: <pre><code>Password: \nCREATE TABLE\n</code></pre></p>"},{"location":"tutorials/golang/#backend-development-golang","title":"\ud83c\udf10 Backend Development (Golang)","text":""},{"location":"tutorials/golang/#install-dependencies","title":"Install Dependencies","text":"<p>Navigate to the backend directory and install dependencies:</p> <pre><code>cd app\ngo mod tidy\n</code></pre>"},{"location":"tutorials/golang/#start-backend-server-live-coding","title":"Start Backend Server (Live Coding)","text":"<p>Run the backend server with live reload using <code>air</code> (or similar tool):</p> <pre><code>air\n</code></pre> <p>Note: (DevSpaces only) Click \"Yes\" if prompted to expose the application outside the workspace.</p>"},{"location":"tutorials/golang/#explore-api-endpoints","title":"Explore API Endpoints","text":"<p>Access the API endpoints directly via your browser or API testing tools like Postman or curl.</p>"},{"location":"tutorials/golang/#testing-the-application","title":"\u2705 Testing the Application","text":"<ol> <li>Verify Functionality:</li> <li>Check message retrieval and display.</li> <li>Test adding new messages.</li> <li>Use ping functionality to verify API health.</li> </ol> <p>Example curl commands:</p> <ul> <li> <p>Health check: <pre><code>curl http://localhost:8080/api/ping\n</code></pre></p> </li> <li> <p>Retrieve messages: <pre><code>curl http://localhost:8080/api\n</code></pre></p> </li> <li> <p>Add a new message: <pre><code>curl -X POST -H \"Content-Type: application/json\" http://localhost:8080/api/add/Hello\n</code></pre></p> </li> </ul> <p>\ud83c\udf89 Congratulations! You've successfully set up and tested your Golang REST API with PostgreSQL.</p>"},{"location":"tutorials/golang/#deploying-backend-on-openshift-using-helm","title":"\ud83d\ude80 Deploying Backend on OpenShift using Helm","text":""},{"location":"tutorials/golang/#steps-to-deploy","title":"Steps to Deploy","text":"<ol> <li>Navigate to the Backend Helm Chart Directory:</li> </ol> <p>Change to the directory containing the Helm chart for the backend:</p> <pre><code>cd openshift-quickstart-manifest/golang/helm\n</code></pre> <ol> <li>Deploy the Backend using Helm:</li> </ol> <p>Use the following command to deploy the backend application on OpenShift:</p> <pre><code>helm dependency build\nhelm install golang-backend .\n</code></pre> <p>This command will deploy the backend application using the Helm chart located in the current directory.</p> <ol> <li>Verify Deployment:</li> </ol> <p>Check the status of the deployed pods to ensure everything is running smoothly:</p> <pre><code>oc get pods -lapp.kubernetes.io/instance=golang-backend\n</code></pre> <p>You should see the backend and postgres pods up and running.</p> <ol> <li>Access the Backend Service:</li> </ol> <p>Once deployed, you can access the backend service using the route created by OpenShift. Retrieve the route with:</p> <pre><code>oc get routes golang-backend\n</code></pre> <p>Use the URL provided to interact with your backend API.</p>"},{"location":"tutorials/golang/#bonus-switch-the-angular-frontend-to-use-the-golang-backend","title":"\ud83d\ude80 Bonus: Switch the Angular Frontend to Use the Golang Backend","text":""},{"location":"tutorials/helm%2Bkustomize/","title":"Helm and Kustomize","text":"<p>This tutorial introduces Helm and Kustomize, two powerful Kubernetes configuration management tools.  You'll learn the basics of each tool through practical exercises and see how combining them can simplify and enhance your Kubernetes deployments.</p> <p>The code examples and instructions in this tutorial are located under <code>openshift-quickstart</code> project in the <code>tutorials/helm+kustomize</code> directory. </p> <p>Ensure you are in this directory before executing the commands. </p> <ol> <li> <p>Navigate to the Tutorial Directory     <pre><code>cd openshift-quickstart/tutorials/helm+kustomize\n</code></pre></p> </li> <li> <p>Or open a New Terminal</p> </li> </ol>"},{"location":"tutorials/helm%2Bkustomize/#exercises","title":"Exercises","text":""},{"location":"tutorials/helm%2Bkustomize/#exercise-1-helm-basics","title":"Exercise 1: Helm Basics","text":"<p>Deploy a simple application using Helm.</p> <ol> <li>Create a Helm Chart    <pre><code>helm create myapp\n</code></pre></li> <li>Edit/Update <code>values.yaml</code> to customize your deployment:      <pre><code> image:\n   repository: registry.redhat.io/ubi9/python-312\n   tag: latest\n\n service:\n   type: ClusterIP\n   port: 8000\n</code></pre></li> <li> <p>Edit <code>templates/deployment.yaml</code> to add the python3 startup command:    <pre><code>spec:\n  template:\n    spec:\n      containers:\n      - name: {{ Chart.Name }}\n        command: [\"python3\"]\n        args: [\"-m\", \"http.server\"]\n</code></pre></p> </li> <li> <p>Deploy the Chart    <pre><code>helm install myapp-release ./myapp\n</code></pre></p> </li> <li>Verify Deployment    <pre><code>oc get pods\n</code></pre></li> </ol>"},{"location":"tutorials/helm%2Bkustomize/#exercise-2-kustomize-basics","title":"Exercise 2: Kustomize Basics","text":"<p>Deploy the same application using Kustomize.</p> <ol> <li>Create a directory structure:      <pre><code>myapp/\n\u251c\u2500\u2500 base/\n\u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u251c\u2500\u2500 service.yaml\n\u2502   \u2514\u2500\u2500 kustomization.yaml\n\u2514\u2500\u2500 overlays/\n    \u2514\u2500\u2500 dev/\n        \u2514\u2500\u2500 kustomization.yaml\n</code></pre></li> <li>Populate <code>deployment.yaml</code> and <code>service.yaml</code> with basic Kubernetes manifests.</li> <li> <p>Create <code>deployment.yaml</code>:      <pre><code> apiVersion: apps/v1\n kind: Deployment\n metadata:\n   name: myapp-k\n spec:\n   replicas: 1\n   selector:\n     matchLabels:\n       app: myapp-k\n   template:\n     metadata:\n       labels:\n         app: myapp-k\n     spec:\n       containers:\n       - name: nginx\n         image: registry.redhat.io/ubi9/nginx-122:latest\n         command: [\"nginx\"]\n         args: [\"-g\", \"daemon off;\"]\n         ports:\n         - containerPort: 8080\n         resources:\n           limits:\n             cpu: \"500m\"\n             memory: \"256Mi\"\n           requests:\n             cpu: \"200m\" \n             memory: \"128Mi\"\n</code></pre></p> </li> <li> <p>Create <code>service.yaml</code>:      <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-k\nspec:\n  selector:\n    app: myapp-k\n  ports:\n  - port: 8080\n    targetPort: 8080\n  type: ClusterIP\n</code></pre></p> </li> <li> <p>In <code>overlays/dev/kustomization.yaml</code>, reference the base and apply customizations:      <pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nresources:\n  - ../../base\npatches:\n  - path: deployment-patch.yaml\n</code></pre></p> </li> <li> <p>Create <code>deployment-patch.yaml</code>:      <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-k\nspec:\n  replicas: 2\n</code></pre></p> </li> <li> <p>Deploy with Kustomize**    <pre><code># The -k flag tells oc/kubectl to process the directory as a kustomization\noc apply -k overlays/dev\n</code></pre></p> </li> <li> <p>Verify Deployment**    <pre><code>oc get pods\n</code></pre></p> </li> </ol>"},{"location":"tutorials/helm%2Bkustomize/#exercise-3-using-kustomize-with-helm-charts-enable-helm","title":"Exercise 3: Using Kustomize with Helm Charts (<code>--enable-helm</code>)","text":"<p>Leverage Kustomize's built-in Helm integration to directly manage Helm charts without manually rendering templates.</p> <ol> <li> <p>Create Directory Structure    <pre><code>mkdir -p helm-k/overlays/prod\n</code></pre></p> </li> <li> <p>Create a Sample Helm Chart    <pre><code># Create charts directory\nmkdir -p helm-k/overlays/prod/charts\ncd helm-k/overlays/prod/charts\n\n# Create a sample Helm chart\nhelm create myapp\n\n# Return to the base directory\ncd ../../..\n</code></pre></p> </li> </ol> <p>This will create a basic Helm chart structure with default templates and values.</p> <ol> <li> <p>Define Kustomization with Helm Chart    Create a <code>kustomization.yaml</code> file in <code>helm-k/overlays/prod</code>:    <pre><code> apiVersion: kustomize.config.k8s.io/v1beta1\n kind: Kustomization\n\n helmGlobals:\n   chartHome: ./charts\n helmCharts:\n   - name: myapp\n     releaseName: myapp-prod\n     namespace: prod\n     valuesInline:\n       replicaCount: 2\n</code></pre></p> </li> <li> <p>Build Using Kustomize with Helm Enabled and check the replicas    <pre><code>kustomize build --enable-helm helm-k/overlays/prod |grep replicas\n</code></pre></p> </li> </ol>"},{"location":"tutorials/helm%2Bkustomize/#explanation","title":"Explanation","text":"<ul> <li>The <code>--enable-helm</code> flag allows Kustomize to directly process Helm charts, simplifying the workflow by eliminating the need to manually run <code>helm template</code>.</li> <li>Inline values (<code>valuesInline</code>) provide a convenient way to customize Helm chart parameters directly within the Kustomize configuration.</li> </ul>"},{"location":"tutorials/java/","title":"Java Stack Tutorial","text":"<p>Welcome to the Java Stack repository! This repository provides practical, hands-on examples to help you quickly learn and master popular Java frameworks and tools. Each project is designed to guide you through the essentials of building, running, and debugging Java applications.</p>"},{"location":"tutorials/java/#whats-included","title":"What's Included?","text":""},{"location":"tutorials/java/#1-quarkus-hello-world-application","title":"1. Quarkus Hello World Application","text":"<p>Explore Quarkus, a high-performance Java framework optimized for cloud-native applications. This simple example will help you quickly grasp the basics of Quarkus.</p> <ul> <li>Quarkus Official Documentation</li> <li>Quarkus Guides and Tutorials</li> <li>Getting Started with Quarkus</li> </ul>"},{"location":"tutorials/java/#2-spring-boot-sample-application","title":"2. Spring Boot Sample Application","text":"<p>Dive into Spring Boot, a powerful and widely-used framework for creating production-ready Java applications. This sample project demonstrates core Spring Boot concepts clearly and effectively.</p> <ul> <li>Spring Boot Official Documentation</li> <li>VSCode Java Development Guide</li> <li>Getting Started with Spring Boot</li> </ul>"},{"location":"tutorials/java/#how-to-get-started","title":"How to Get Started","text":"<p>Each project includes detailed step-by-step instructions to help you:</p> <ul> <li>Build your application from scratch.</li> <li>Run your application locally or in a containerized environment.</li> <li>Debug your application effectively using modern tools.</li> </ul> <p>Simply navigate to the respective project directories to find comprehensive guides:</p> <ul> <li>Quarkus Hello World Application Guide</li> <li>Spring Boot Sample Application Guide</li> </ul>"},{"location":"tutorials/java/quarkus/","title":"Quarkus Hello World Application","text":"<p>This tutorial guides you through building and running a simple REST API using Quarkus and PostgreSQL.</p>"},{"location":"tutorials/java/quarkus/#tutorial","title":"Tutorial","text":"<p>The code examples and instructions in this tutorial are located under the <code>openshift-quickstart</code> project in the <code>tutorials/java/quarkus</code> directory. Ensure you are in this directory before executing the commands.</p> <ol> <li> <p>Navigate to the Tutorial Directory <pre><code>cd openshift-quickstart/tutorials/java/quarkus\n</code></pre></p> </li> <li> <p>Or open a New Terminal</p> </li> </ol>"},{"location":"tutorials/java/quarkus/#features","title":"\ud83d\ude80 Features","text":""},{"location":"tutorials/java/quarkus/#backend-quarkus-rest-api","title":"Backend (Quarkus REST API)","text":"<ul> <li>Provides RESTful endpoints.</li> <li>Secure database interactions using prepared statements (PostgreSQL).</li> <li>Implements API health check (ping functionality).</li> </ul>"},{"location":"tutorials/java/quarkus/#initial-setup","title":"\ud83d\udee0\ufe0f Initial Setup","text":""},{"location":"tutorials/java/quarkus/#prerequisite-spin-up-postgresql-container-on-laptop","title":"Prerequisite: Spin Up PostgreSQL Container on Laptop","text":"<p>To set up a PostgreSQL container locally, follow these steps:</p> <ol> <li>Run PostgreSQL Container:</li> </ol> <p>Start a new PostgreSQL container with the following command:</p> <pre><code>podman run -d -v $(pwd):/projects -e POSTGRESQL_USER=user -e POSTGRESQL_PASSWORD=pass -e POSTGRESQL_ROOT_PASSWORD=root -e POSTGRESQL_DATABASE=db -p 5432:5432 registry.redhat.io/rhel9/postgresql-16:latest\n</code></pre> <ol> <li>Verify Container is Running:</li> </ol> <p>Check that your PostgreSQL container is running:</p> <pre><code>podman ps\n</code></pre>"},{"location":"tutorials/java/quarkus/#database-configuration-first-time-setup","title":"Database Configuration (First-time setup)","text":"<p>The Quarkus application will automatically initialize the database schema on first startup. The schema creation is handled by Hibernate ORM using the entity classes defined in the application.</p> <p>You can verify the schema creation by checking the application logs during startup:</p>"},{"location":"tutorials/java/quarkus/#building-the-application","title":"Building the Application","text":"<p>To build the application, use the following Maven command:</p> <pre><code>cd quarkus\nmvn clean package\n</code></pre> <p>This command will compile the project and package it into a JAR file located in the <code>target/quarkus-app/</code> directory.</p>"},{"location":"tutorials/java/quarkus/#running-the-application","title":"Running the Application","text":"<p>You can run the application like normal java app.</p> <pre><code>java -jar target/quarkus-app/quarkus-run.jar\n</code></pre> <p>Or you can run your application in development mode, which enables live coding, using:</p> <pre><code>mvn quarkus:dev\n</code></pre> <p>Expose the endpoint and access the application.</p> <p> </p>"},{"location":"tutorials/java/quarkus/#debugging-with-vscode","title":"Debugging with VSCode","text":"<ol> <li>Configure Launch Settings:    Create a <code>launch.json</code> file in the <code>.vscode</code> directory with the following configuration:</li> </ol> <pre><code>{\n  \"version\": \"0.2.0\",\n  \"configurations\": [\n    {\n      \"type\": \"java\",\n      \"name\": \"Quarkus Debug (Attach)\",\n      \"request\": \"attach\",\n      \"hostName\": \"localhost\",\n      \"port\": 5005\n    }\n  ]\n}\n</code></pre> <ol> <li>Start the Application in Debug Mode:    Run the application with debugging enabled:</li> </ol> <pre><code>mvn quarkus:dev\n</code></pre> <ol> <li>Attach the Debugger</li> </ol> <p>In VSCode, go to the Run and Debug view, and select \"Quarkus Debug (Attach)\" to start debugging.</p> <p></p>"},{"location":"tutorials/java/quarkus/#packaging-the-application","title":"Packaging the Application","text":"<p>To package the application execute:</p> <pre><code>mvn package\n</code></pre> <p>Run the packaged application using:</p> <pre><code>java -jar target/quarkus-app/quarkus-run.jar\n</code></pre>"},{"location":"tutorials/java/quarkus/#build-the-image","title":"Build the Image","text":"<p>Use the following command to build the image. This command uses the Dockerfile located at <code>src/main/docker/Dockerfile.jvm</code>:</p> <pre><code>podman build -f src/main/docker/Dockerfile.jvm -t quarkus:latest .\n</code></pre> <ol> <li>Run the Docker Container:    Once the image is built, you can run the container using:</li> </ol> <p>```bash    podman run quarkus:latest -p 8080:8080    ````</p>"},{"location":"tutorials/java/quarkus/#optional-creating-a-native-executable","title":"(Optional) Creating a Native Executable","text":"<p>Note: Building a native executable can be resource-intensive and may require significant CPU and memory resources. Ensure your system has sufficient resources available before proceeding.</p> <p>You can create a native executable using:</p> <pre><code>mvn package -Pnative\n</code></pre> <p>Run the native executable with:</p> <pre><code>./target/quarkus-1.0.0-SNAPSHOT-runner -Dquarkus.http.port=8081\n</code></pre>"},{"location":"tutorials/java/quarkus/#explore-api-endpoints","title":"Explore API Endpoints","text":"<p>Access the API endpoints directly via your browser or API testing tools like Postman or curl.</p>"},{"location":"tutorials/java/quarkus/#testing-the-application","title":"\u2705 Testing the Application","text":"<ol> <li>Verify Functionality:</li> <li>Check message retrieval and display.</li> <li>Test adding new messages.</li> <li>Use ping functionality to verify API health.</li> </ol> <p>Example curl commands:</p> <ul> <li> <p>Health check: <pre><code>curl http://localhost:8080/api/ping\n</code></pre></p> </li> <li> <p>Retrieve messages: <pre><code>curl http://localhost:8080/api\n</code></pre></p> </li> <li> <p>Add a new message: <pre><code>curl -X POST -H \"Content-Type: application/json\" http://localhost:8080/api/add/Hello\n</code></pre></p> </li> </ul> <p>\ud83c\udf89 Congratulations! You've successfully set up and tested your Quarkus REST API with PostgreSQL.</p>"},{"location":"tutorials/java/quarkus/#deploying-backend-on-openshift-using-helm","title":"\ud83d\ude80 Deploying Backend on OpenShift using Helm","text":""},{"location":"tutorials/java/quarkus/#steps-to-deploy","title":"Steps to Deploy","text":"<ol> <li>Navigate to the Backend Helm Chart Directory:</li> </ol> <p>Change to the directory containing the Helm chart for the backend:</p> <pre><code>cd openshift-quickstart-manifest/java/helm\n</code></pre> <ol> <li>Deploy the Backend using Helm:</li> </ol> <p>Use the following command to deploy the backend application on OpenShift:</p> <pre><code>helm dependency build\nhelm install quarkus-backend .\n</code></pre> <p>This command will deploy the backend application using the Helm chart located in the current directory.</p> <ol> <li>Verify Deployment:</li> </ol> <p>Check the status of the deployed pods to ensure everything is running smoothly:</p> <pre><code>oc get pods -lapp.kubernetes.io/instance=quarkus-backend\n</code></pre> <p>You should see the backend and postgres pods up and running.</p> <ol> <li>Access the Backend Service:</li> </ol> <p>Once deployed, you can access the backend service using the route created by OpenShift. Retrieve the route with:</p> <pre><code>oc get routes quarkus-backend\n</code></pre> <p>Use the URL provided to interact with your backend API.</p>"},{"location":"tutorials/java/quarkus/#bonus-switch-the-angular-frontend-to-use-the-quarkus-backend","title":"\ud83d\ude80 Bonus: Switch the Angular Frontend to Use the Quarkus Backend","text":""},{"location":"tutorials/java/springboot/","title":"Spring Boot Sample Application","text":"<p>This tutorial guides you through building and running a simple REST API using SpringBoot and PostgreSQL.</p>"},{"location":"tutorials/java/springboot/#tutorial","title":"Tutorial","text":"<p>The code examples and instructions in this tutorial are located under the <code>openshift-quickstart</code> project in the <code>tutorials/java/springboot</code> directory. Ensure you are in this directory before executing the commands.</p> <ol> <li> <p>Navigate to the Tutorial Directory <pre><code>cd openshift-quickstart/tutorials/java/springboot\n</code></pre></p> </li> <li> <p>Or open a New Terminal</p> </li> </ol>"},{"location":"tutorials/java/springboot/#features","title":"\ud83d\ude80 Features","text":""},{"location":"tutorials/java/springboot/#backend-springboot-rest-api","title":"Backend (SpringBoot REST API)","text":"<ul> <li>Provides RESTful endpoints.</li> <li>Secure database interactions using prepared statements (PostgreSQL).</li> <li>Implements API health check (ping functionality).</li> </ul>"},{"location":"tutorials/java/springboot/#initial-setup","title":"\ud83d\udee0\ufe0f Initial Setup","text":""},{"location":"tutorials/java/springboot/#prerequisite-spin-up-postgresql-container-on-laptop","title":"Prerequisite: Spin Up PostgreSQL Container on Laptop","text":"<p>To set up a PostgreSQL container locally, follow these steps:</p> <ol> <li>Run PostgreSQL Container:</li> </ol> <p>Start a new PostgreSQL container with the following command:</p> <pre><code>podman run -d -v $(pwd):/projects -e POSTGRESQL_USER=user -e POSTGRESQL_PASSWORD=pass -e POSTGRESQL_ROOT_PASSWORD=root -e POSTGRESQL_DATABASE=db -p 5432:5432 registry.redhat.io/rhel9/postgresql-16:latest\n</code></pre> <ol> <li>Verify Container is Running:</li> </ol> <p>Check that your PostgreSQL container is running:</p> <pre><code>podman ps\n</code></pre>"},{"location":"tutorials/java/springboot/#database-configuration-first-time-setup","title":"Database Configuration (First-time setup)","text":"<p>The SpringBoot application will automatically initialize the database schema on first startup. The schema creation is handled by Hibernate ORM using the entity classes defined in the application.</p> <p>You can verify the schema creation by checking the application logs during startup:</p>"},{"location":"tutorials/java/springboot/#building-the-application","title":"Building the Application","text":"<p>To build the application, use the following Maven command:</p> <pre><code>cd springboot\nmvn clean package\n</code></pre> <p>This command will compile the project and package it into a JAR file located in the <code>target/</code> directory.</p>"},{"location":"tutorials/java/springboot/#running-the-application","title":"Running the Application","text":"<p>You can run the application like normal java app.</p> <pre><code>java -jar target/boot-0.0.1-SNAPSHOT.jar\n</code></pre> <p>Or you can run your application in development mode, which enables live coding, using:</p> <pre><code>mvn spring-boot:run\n</code></pre> <p>Expose the endpoint and access the application.</p> <p></p>"},{"location":"tutorials/java/springboot/#debugging-with-vscode","title":"Debugging with VSCode","text":"<p>It is already defined in the project. </p> <ol> <li>Run in VSCode:</li> <li>Open the project in VSCode.</li> <li>Navigate to the <code>BootApplication.java</code> file.</li> <li>Click on the <code>Run</code> button above the <code>main</code> method or use the <code>Run</code> menu.</li> </ol>"},{"location":"tutorials/java/springboot/#debugging-the-application","title":"Debugging the Application","text":"<ol> <li>Debug in VSCode:</li> <li>Set breakpoints in your Java files.</li> <li>Open the <code>Run and Debug</code> panel in VSCode (Ctrl+Shift+D).</li> <li>Click on <code>Run and Debug</code> and select <code>Java</code> environment.</li> <li>The application will start in debug mode, and execution will pause at your breakpoints.</li> </ol>"},{"location":"tutorials/java/springboot/#building-the-container","title":"Building the Container","text":"<p>To build a container for your Quarkus application, follow these steps:</p>"},{"location":"tutorials/java/springboot/#steps","title":"Steps","text":"<ol> <li>Ensure the Application is Packaged:    Before building the Docker image, make sure your application is packaged. You can do this by running:</li> </ol> <pre><code>mvn package\n</code></pre> <ol> <li>Build the Image:    Use the following command to build the image. This command uses the Dockerfile located at <code>src/main/docker/Dockerfile.jvm</code>:</li> </ol> <pre><code>podman build -f src/main/docker/Dockerfile.jvm -t boot:latest .\n</code></pre> <ol> <li>Run the Docker Container:    Once the image is built, you can run the container using:</li> </ol> <pre><code>podman run boot:latest -p 8080:8080 \n</code></pre> <p>These steps will help you build and run your Spring Boot application in a container, allowing for easy deployment and testing.</p>"},{"location":"tutorials/java/springboot/#explore-api-endpoints","title":"Explore API Endpoints","text":"<p>Access the API endpoints directly via your browser or API testing tools like Postman or curl.</p>"},{"location":"tutorials/java/springboot/#testing-the-application","title":"\u2705 Testing the Application","text":"<ol> <li>Verify Functionality:</li> <li>Check message retrieval and display.</li> <li>Test adding new messages.</li> <li>Use ping functionality to verify API health.</li> </ol> <p>Example curl commands:</p> <ul> <li> <p>Health check: <pre><code>curl http://localhost:8080/api/ping\n</code></pre></p> </li> <li> <p>Retrieve messages: <pre><code>curl http://localhost:8080/api\n</code></pre></p> </li> <li> <p>Add a new message: <pre><code>curl -X POST -H \"Content-Type: application/json\" http://localhost:8080/api/add/Hello\n</code></pre></p> </li> </ul> <p>\ud83c\udf89 Congratulations! You've successfully set up and tested your Quarkus REST API with PostgreSQL.</p>"},{"location":"tutorials/java/springboot/#deploying-backend-on-openshift-using-helm","title":"\ud83d\ude80 Deploying Backend on OpenShift using Helm","text":""},{"location":"tutorials/java/springboot/#steps-to-deploy","title":"Steps to Deploy","text":"<ol> <li>Navigate to the Backend Helm Chart Directory:</li> </ol> <p>Change to the directory containing the Helm chart for the backend:</p> <pre><code>cd openshift-quickstart-manifest/java/helm\n</code></pre> <ol> <li>Deploy the Backend using Helm:</li> </ol> <p>Use the following command to deploy the backend application on OpenShift:</p> <pre><code>helm dependency build\nhelm install springboot-backend . -f values-boot.yaml\n</code></pre> <p>This command will deploy the backend application using the Helm chart located in the current directory.</p> <ol> <li>Verify Deployment:</li> </ol> <p>Check the status of the deployed pods to ensure everything is running smoothly:</p> <pre><code>oc get pods -lapp.kubernetes.io/instance=springboot-backend\n</code></pre> <p>You should see the backend and postgres pods up and running.</p> <ol> <li>Access the Backend Service:</li> </ol> <p>Once deployed, you can access the backend service using the route created by OpenShift. Retrieve the route with:</p> <pre><code>oc get routes springboot-backend\n</code></pre> <p>Use the URL provided to interact with your backend API.</p>"},{"location":"tutorials/java/springboot/#bonus-switch-the-angular-frontend-to-use-the-spring-boot-backend","title":"\ud83d\ude80 Bonus: Switch the Angular Frontend to Use the Spring Boot Backend","text":""},{"location":"tutorials/js/","title":"NodeJS Express API with Angular Client (Material Design)","text":"<p>This tutorial guides you through building and running a simple REST API using NodeJS Express and an Angular client application with Material Design.</p>"},{"location":"tutorials/js/#tutorial","title":"Tutorial","text":"<p>The code examples and instructions in this tutorial are located under <code>openshift-quickstart</code> project in the <code>tutorials/js</code> directory.  Ensure you are in this directory before executing the commands. </p> <ol> <li> <p>Navigate to the Tutorial Directory     <pre><code># Change to the tutorials/simple directory\ncd openshift-quickstart/tutorials/js\n</code></pre></p> </li> <li> <p>Or open a New Terminal</p> </li> </ol>"},{"location":"tutorials/js/#features","title":"\ud83d\ude80 Features","text":""},{"location":"tutorials/js/#backend-nodejs-express-api","title":"Backend (NodeJS Express API)","text":"<ul> <li>Provides RESTful endpoints (OpenAPI Specification).</li> <li>Secure database interactions using prepared statements (PostgreSQL).</li> </ul>"},{"location":"tutorials/js/#frontend-angular-client","title":"Frontend (Angular Client)","text":"<ul> <li>Fetches and displays messages from the API.</li> <li>Allows adding new messages.</li> <li>Implements API health check (ping functionality).</li> <li>Uses Material Design for a visually appealing interface.</li> </ul>"},{"location":"tutorials/js/#initial-setup","title":"\ud83d\udee0\ufe0f Initial Setup","text":""},{"location":"tutorials/js/#prerequisite-spin-up-postgresql-container-on-laptop","title":"Prerequisite: Spin Up PostgreSQL Container on Laptop","text":"<p>To set up a PostgreSQL container locally, follow these steps:</p> <ol> <li>Run PostgreSQL Container:</li> </ol> <p>Start a new PostgreSQL container with the following command:</p> <pre><code>podman run -d -v $(pwd):/projects -e POSTGRESQL_USER=user -e POSTGRESQL_PASSWORD=pass -e POSTGRESQL_ROOT_PASSWORD=root -e POSTGRESQL_DATABASE=db -p 5432:5432 registry.redhat.io/rhel9/postgresql-16:latest\n</code></pre> <ol> <li>Verify Container is Running:</li> </ol> <p>Check that your PostgreSQL container is running:</p> <pre><code>podman ps\n</code></pre>"},{"location":"tutorials/js/#database-configuration-first-time-setup","title":"Database Configuration (First-time setup)","text":"<ol> <li>Open Terminal on PostgreSQL container:</li> </ol> <ol> <li>Access PostgreSQL Container:</li> </ol> <p>To access the running PostgreSQL container, execute the following command, replacing <code>&lt;containerId&gt;</code> with the actual container ID obtained from the <code>podman ps</code> command:</p> <pre><code>podman exec -it &lt;containerId&gt; bash\n</code></pre> <p>This command will open an interactive terminal session inside the PostgreSQL container, allowing you to run database commands directly.</p> <ol> <li>Initialize Database Schema:</li> </ol> <p>Execute the following command in the terminal (password: <code>pass</code>):</p> <pre><code>cd /projects\npsql -d db -U user -W -f tutorials/js/backend/db/schema.sql\n</code></pre> <p>Expected Output: <pre><code>Password: \nCREATE TABLE\n</code></pre></p>"},{"location":"tutorials/js/#backend-development-nodejs","title":"\ud83c\udf10 Backend Development (NodeJS)","text":""},{"location":"tutorials/js/#install-dependencies","title":"Install Dependencies","text":"<p>Navigate to the backend directory and install dependencies:</p> <pre><code>cd backend/app\nnpm install\n</code></pre>"},{"location":"tutorials/js/#start-backend-server-live-coding","title":"Start Backend Server (Live Coding)","text":"<p>Run the backend server with live reload using <code>nodemon</code>:</p> <pre><code>npm run startdev\n</code></pre> <p></p> <p>Note: (DevSpaces only) Click \"Yes\" if prompted to expose the application outside the workspace.</p>"},{"location":"tutorials/js/#explore-api-endpoints","title":"Explore API Endpoints","text":"<p>Access the OpenAPI Specification directly under <code>backend/app</code> to test endpoints interactively.</p> <p> </p>"},{"location":"tutorials/js/#frontend-development-angular","title":"\ud83c\udfa8 Frontend Development (Angular)","text":""},{"location":"tutorials/js/#install-dependencies_1","title":"Install Dependencies","text":"<p>Navigate to the frontend directory and install dependencies:</p> <pre><code>cd frontend/app\nnpm install\n</code></pre>"},{"location":"tutorials/js/#start-frontend-application-live-coding","title":"Start Frontend Application (Live Coding)","text":"<p>Launch the Angular application with live reload:</p> <pre><code>npm start\n</code></pre> <p></p>"},{"location":"tutorials/js/#testing-the-application","title":"\u2705 Testing the Application","text":"<ol> <li>Access Frontend Application:</li> </ol> <p>From the endpoint section, click the provided link to open the frontend application.</p> <p></p> <ol> <li>Verify Functionality:</li> <li>Check message retrieval and display.</li> <li>Test adding new messages.</li> <li>Use ping functionality to verify API health.</li> </ol>"},{"location":"tutorials/js/#additional-resources","title":"\ud83d\udccc Additional Resources","text":"<ul> <li>Angular Documentation</li> <li>ExpressJS Documentation</li> <li>Material Design Components</li> </ul> <p>\ud83c\udf89 Congratulations! You've successfully set up and tested your NodeJS Express API with an Angular client using Material Design.</p>"},{"location":"tutorials/js/#deploying-backend-on-openshift-using-helm","title":"\ud83d\ude80 Deploying Backend on OpenShift using Helm","text":""},{"location":"tutorials/js/#steps-to-deploy","title":"Steps to Deploy","text":"<ol> <li>Navigate to the Backend Helm Chart Directory:</li> </ol> <p>Change to the directory containing the Helm chart for the backend:</p> <pre><code>cd openshift-quickstart-manifest/js/backend/helm\n</code></pre> <ol> <li>Deploy the Backend using Helm:</li> </ol> <p>Use the following command to deploy the backend application on OpenShift:</p> <pre><code># Note: This command ensures all chart dependencies, including the PostgreSQL chart in our case, are up-to-date before installation.\nhelm dependency build\n\nhelm install js-backend .\n</code></pre> <p>This command will deploy the backend application using the Helm chart located in the current directory.</p> <ol> <li>Verify Deployment:</li> </ol> <p>Check the status of the deployed pods to ensure everything is running smoothly:</p> <pre><code>oc get pods -lapp.kubernetes.io/instance=js-backend\n</code></pre> <p>You should see the backend and postgres pods up and running.</p> <ol> <li>Access the Backend Service:</li> </ol> <p>Once deployed, you can access the backend service using the route created by OpenShift. Retrieve the route with:</p> <pre><code>oc get routes js-backend\n</code></pre> <p>Use the URL provided to interact with your backend API.</p>"},{"location":"tutorials/js/#deploying-frontend-on-openshift-using-helm","title":"\ud83d\ude80 Deploying Frontend on OpenShift using Helm","text":""},{"location":"tutorials/js/#steps-to-deploy_1","title":"Steps to Deploy","text":"<ol> <li>Navigate to the Frontend Helm Chart Directory:</li> </ol> <p>Change to the directory containing the Helm chart for the frontend:</p> <pre><code>cd openshift-quickstart-manifest/js/frontend/helm\n</code></pre> <p>Note: Before deploying the frontend, ensure that the following values in the <code>values.yaml</code> file are correctly set: - <code>baseDomain</code>: This should be set to the domain of your OpenShift cluster. - <code>backendName</code>: This should match the name of the backend service you deployed. By default, it is set to <code>js-backend</code>.</p> <p>These values are crucial for the frontend to correctly interact with the backend service and be accessible via the OpenShift routes.</p> <pre><code>baseDomain: apps.cluster-2jp75.2jp75.sandbox2851.opentlc.com\nbackendName: js-backend\n</code></pre> <ol> <li>Deploy the Frontend using Helm:</li> </ol> <p>Use the following command to deploy the frontend application on OpenShift:</p> <pre><code>helm install js-frontend .\n</code></pre> <p>This command will deploy the frontend application using the Helm chart located in the current directory.</p> <ol> <li>Verify Deployment:</li> </ol> <p>Check the status of the deployed pods to ensure everything is running smoothly:</p> <pre><code>oc get pods -lapp.kubernetes.io/instance=js-frontend\n</code></pre> <p>You should see the frontend pod up and running.</p> <ol> <li>Access the Frontend Service:</li> </ol> <p>Once deployed, you can access the frontend service using the route created by OpenShift. Retrieve the route with:</p> <pre><code>oc get routes js-frontend\n</code></pre> <p>Use the URL provided to interact with your frontend application.</p> <ol> <li>Test Interaction with Backend:</li> </ol> <p>Open the frontend application in your browser using the URL obtained in the previous step. Verify that the frontend can successfully interact with the backend API by performing actions that require backend communication, such as fetching or adding messages.</p> <p>If the frontend is unable to communicate with the backend, ensure that the backend service URL is correctly configured in the frontend application settings.</p>"},{"location":"tutorials/networkpolicy/","title":"Network Policy","text":""},{"location":"tutorials/networkpolicy/#tutorial","title":"Tutorial","text":"<p>The code examples and instructions in this tutorial are located under <code>openshift-quickstart</code> project in the <code>tutorials/networkpolicy</code> directory. </p> <p>Ensure you are in this directory before executing the commands. </p> <ol> <li> <p>Navigate to the Tutorial Directory     <pre><code>cd openshift-quickstart/tutorials/networkpolicy\n</code></pre></p> </li> <li> <p>Or open a New Terminal</p> </li> </ol>"},{"location":"tutorials/networkpolicy/#steps","title":"Steps","text":"<p>Note: At this point, you should have at least one Python pods up and running in your namespace.</p> <ol> <li> <p>Deploy a new Python pod with a different name and labels to test network policies.</p> <p>Use the following YAML configuration: <pre><code>---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: python-server-second\n  labels:\n    app: python-server-second\nspec:\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: python-server-container\n    image: registry.redhat.io/ubi9/python-312\n    ports:\n    - containerPort: 8000\n    command: [\"python3\", \"-m\", \"http.server\"]\n    resources:\n      limits:\n        cpu: \"0.5\"\n        memory: \"512Mi\"\n      requests:\n        cpu: \"0.2\"\n        memory: \"256Mi\"\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop: [\"ALL\"]\n      readOnlyRootFilesystem: true\n    livenessProbe:\n      httpGet:\n        path: /\n        port: 8000\n      initialDelaySeconds: 3\n      periodSeconds: 3\n</code></pre> 2. Expose the <code>python-server-second</code> pod with a service to enable network communication.</p> <p>Use the following YAML configuration: <pre><code>---\napiVersion: v1\nkind: Service\nmetadata:\n  name: python-server-second-service\nspec:\n  selector:\n    app: python-server-second\n  ports:\n    - protocol: TCP\n      port: 8000\n      targetPort: 8000\n</code></pre></p> </li> <li> <p>Verify that all communication is allowed within the namespace.</p> <p>Execute the following command to test connectivity to the <code>python-server-second-service</code> service. <pre><code>oc rsh python-server-pod\ncurl -I http://python-server-second-service:8000\nexit\n</code></pre> Use this command to test connectivity to the <code>python-server-service</code> on port 8000. <pre><code>oc rsh python-server-second\ncurl -I http://python-server-service:8000\n</code></pre></p> </li> <li> <p>Restrict the traffic to your <code>python-server-service</code> service by applying a deny policy.     <pre><code>oc create -f deny.yaml\n</code></pre></p> </li> <li> <p>Check the connectivity from the second Python pod to ensure the deny policy is in effect.     <pre><code>curl -I http://python-server-service:8000 -v\n</code></pre></p> </li> <li> <p>Re-enable specific traffic to the <code>devspaces-userX</code> namespace by applying an allow policy.     <pre><code>oc create -f allow.yaml\n</code></pre></p> </li> <li> <p>Verify that the allow policy is functioning correctly by testing connectivity again.</p> <p>Execute: <pre><code>curl -I http://python-server-service:8000\n</code></pre></p> </li> </ol>"},{"location":"tutorials/networkpolicy/#exercises","title":"Exercises","text":""},{"location":"tutorials/networkpolicy/#exercise-1-a-third-pod","title":"Exercise 1: A third pod","text":"<ol> <li> <p>Deploy a new Python pod named <code>python-server-third</code> to test network policies.</p> <p>Use the following YAML configuration: <pre><code>---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: python-server-third\n  labels:\n    app: python-server-third\nspec:\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: python-server-container\n    image: registry.redhat.io/ubi9/python-312\n    ports:\n    - containerPort: 8000\n    command: [\"python3\", \"-m\", \"http.server\"]\n    resources:\n      limits:\n        cpu: \"0.5\"\n        memory: \"512Mi\"\n      requests:\n        cpu: \"0.2\"\n        memory: \"256Mi\"\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop: [\"ALL\"]\n      readOnlyRootFilesystem: true\n    livenessProbe:\n      httpGet:\n        path: /\n        port: 8000\n      initialDelaySeconds: 3\n      periodSeconds: 3\n</code></pre></p> </li> <li> <p>Test the connectivity from the <code>python-server-third</code> pod to ensure the deny policy is in effect.     <pre><code>oc rsh python-server-third\ncurl -I http://python-server-service:8000 -v\nexit\n</code></pre></p> </li> <li> <p>Allow communication to the <code>python-server-third</code> pod by applying a new allow policy.</p> <p>Use the following YAML configuration: <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-third-pod-communication\nspec:\n  podSelector:\n    matchLabels:\n      app: python-server\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: python-server-third\n</code></pre></p> </li> <li> <p>Enable the new allow policy to permit traffic from the <code>python-server-third</code> pod.     <pre><code>oc create -f allow-third-pod.yaml\n</code></pre></p> </li> <li> <p>Test connectivity again to ensure the allow policy is functioning correctly.</p> <pre><code>oc rsh python-server-third\ncurl -I http://python-server-service:8000\nexit\n</code></pre> </li> </ol>"},{"location":"tutorials/networkpolicy/#exercise-2-multi-tier-application-network-policies","title":"Exercise 2: Multi-tier Application Network Policies","text":"<ol> <li> <p>Deploy a three-tier application setup with the following components:</p> <p>a. Frontend Pod (Web Server): <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: frontend-pod\n  labels:\n    tier: frontend\n    app: multi-tier-app\nspec:\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: frontend-container\n    image: registry.redhat.io/ubi9/python-312\n    ports:\n    - containerPort: 8080\n    command: [\"python3\", \"-m\", \"http.server\", \"8080\"]\n    resources:\n      limits:\n        cpu: \"0.5\"\n        memory: \"512Mi\"\n      requests:\n        cpu: \"0.2\"\n        memory: \"256Mi\"\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop: [\"ALL\"]\n</code></pre></p> <p>b. API Pod (Application Layer):   <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: api-pod\n  labels:\n    tier: api\n    app: multi-tier-app\nspec:\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: api-container\n    image: registry.redhat.io/ubi9/python-312\n    ports:\n    - containerPort: 5000\n      name: api\n    command: [\"python3\", \"-m\", \"http.server\", \"5000\"]\n    resources:\n      limits:\n        cpu: \"0.5\"\n        memory: \"512Mi\"\n      requests:\n        cpu: \"0.2\"\n        memory: \"256Mi\"\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop: [\"ALL\"]\n</code></pre></p> <p>c. Database Pod: <pre><code>---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: db-config\n  labels:\n    tier: database\n    app: multi-tier-app\ndata:\n  POSTGRESQL_USER: user\n  POSTGRESQL_PASSWORD: pass\n  POSTGRESQL_ROOT_PASSWORD: root\n  POSTGRESQL_DATABASE: db\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: db-pod\n  labels:\n    tier: database\n    app: multi-tier-app\nspec:\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: db-container\n    image: registry.redhat.io/rhel9/postgresql-16:latest\n    ports:\n    - containerPort: 5432\n    envFrom:\n      - configMapRef:\n          name: db-config\n    volumeMounts:\n      - mountPath: /var/lib/pgsql/data\n        name: postgresdata\n    resources:\n      limits:\n        cpu: \"0.5\"\n        memory: \"512Mi\"\n      requests:\n        cpu: \"0.2\"\n        memory: \"256Mi\"\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop: [\"ALL\"]\n  volumes:\n    - name: postgresdata\n      emptyDir: {}\n</code></pre></p> </li> <li> <p>Create corresponding services for each pod:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: frontend-service\nspec:\n  selector:\n    tier: frontend\n  ports:\n    - protocol: TCP\n      port: 8080\n      targetPort: 8080\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: api-service\n  labels:\n    tier: api\nspec:\n  selector:\n    tier: api\n  ports:\n    - protocol: TCP\n      port: 5000\n      targetPort: 5000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: db-service\nspec:\n  selector:\n    tier: database\n  ports:\n    - protocol: TCP\n      port: 5432\n      targetPort: 5432\n</code></pre> </li> <li> <p>Tasks:</p> <p>a. Create a network policy that:</p> <ul> <li>Allows frontend to communicate only with the API layer</li> <li>Allows API layer to communicate only with the database</li> <li>Denies all other traffic between pods</li> <li>Allows external traffic only to the frontend</li> </ul> <p>b. Test the connectivity between different layers:</p> <ul> <li>Test frontend to API communication</li> <li>Test frontend to database communication (should fail)</li> <li>Test API to database communication</li> <li>Test external access to frontend</li> </ul> </li> <li> <p>First, let's create a default deny policy to ensure all traffic is blocked by default:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-all\nspec:\n  podSelector:\n    matchLabels:\n      app: multi-tier-app\n  policyTypes:\n  - Ingress\n  - Egress\n</code></pre> </li> <li> <p>Frontend Network Policy (allows incoming external traffic and outgoing to API):</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: frontend-policy\nspec:\n  podSelector:\n    matchLabels:\n      tier: frontend\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - {}  # Allows all incoming traffic\n  egress:\n  - {}\n</code></pre> </li> <li> <p>API Layer Network Policy (allows frontend traffic and connection to database):</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: api-policy\nspec:\n  podSelector:\n    matchLabels:\n      tier: api\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          tier: frontend\n    ports:\n    - protocol: TCP\n      port: 5000\n  egress: \n  - {}\n</code></pre> </li> <li> <p>Database Network Policy (only allows API layer access):</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: database-policy\nspec:\n  podSelector:\n    matchLabels:\n      tier: database\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          tier: api\n    ports:\n    - protocol: TCP\n      port: 5432\n</code></pre> </li> <li> <p>Testing Commands:</p> </li> </ol> <pre><code># Test frontend to API communication (should succeed)\noc rsh frontend-pod\ncurl -I http://api-service:5000\nexit\n\n# Test frontend to database communication (should fail)\noc rsh frontend-pod\ncurl -I http://db-service:5432\nexit\n\n# Test API to database communication (should succeed)\noc rsh api-pod\ncurl -I http://db-service:5432\nexit\n</code></pre> <ol> <li> <p>Expected Results:</p> <ul> <li>Frontend pod should only be able to communicate with the API service</li> <li>API pod should only be able to communicate with the database service</li> <li>Database pod should only accept connections from the API service</li> <li>Monitoring pod should be able to access all services</li> <li>Any other communication attempts should fail</li> </ul> </li> </ol>"},{"location":"tutorials/python/","title":"Deploying and Testing a Python server","text":""},{"location":"tutorials/python/#tutorial","title":"Tutorial","text":"<p>The code examples and instructions in this tutorial are located under <code>openshift-quickstart</code> project in the <code>tutorials/python</code> directory. </p> <p>Ensure you are in this directory before executing the commands. </p> <ol> <li> <p>Navigate to the Tutorial Directory     <pre><code>cd openshift-quickstart/tutorials/python\n</code></pre></p> </li> <li> <p>Or open a New Terminal</p> </li> </ol>"},{"location":"tutorials/python/#building-the-container-image","title":"Building the Container Image","text":"<ol> <li>Build the Container Image:    Use the following command to build the container image for the Python server:    <pre><code>podman build -t python-server:latest .\n</code></pre></li> </ol>"},{"location":"tutorials/python/#running-the-container","title":"Running the Container","text":"<ol> <li> <p>Run the Container:    Start the container using the image you just built:    <pre><code>podman run python-server:latest\n</code></pre></p> </li> <li> <p>Verify the Container is Running:    Check the status of the running container with:    <pre><code>podman ps\n</code></pre></p> </li> </ol>"},{"location":"tutorials/python/#testing-the-server","title":"Testing the Server","text":"<ol> <li> <p>Test the Server:    Ensure the server is responding by executing:    <pre><code>curl http://localhost:8000\n</code></pre></p> <p>Note: This command will fail at this point since we haven't mapped the container's port to the host yet. We'll fix this in the next step.</p> </li> <li> <p>Relaunch the Container with Port Mapping:    To map the container's port to the host, use:    <pre><code>podman run -p8000:8000 python-server:latest\n</code></pre></p> </li> <li> <p>Test the Server Again:    Verify the server is accessible with:    <pre><code>curl http://localhost:8000\n</code></pre></p> </li> </ol>"},{"location":"tutorials/python/#deploying-with-podman","title":"Deploying with Podman","text":"<ol> <li> <p>Create a Pod:    Deploy the application as a pod with port publishing:    <pre><code>podman play kube --publish 8000:8000 pod.yaml\n</code></pre></p> </li> <li> <p>Verify Pod is Running:    Check the status of the pod and its containers:    <pre><code>podman pod ps\npodman ps\n</code></pre></p> </li> <li> <p>Stop and Remove the Pod:    To stop and remove the pod, use:    <pre><code>podman pod stop &lt;podId&gt;\npodman pod rm &lt;podId&gt;\n</code></pre></p> </li> </ol>"},{"location":"tutorials/python/#deploying-to-openshift","title":"Deploying to OpenShift","text":"<ol> <li> <p>Create Resources in OpenShift:</p> <p>Switch to the desired project and create resources:</p> <p>If you are using DevSpaces, you are already logged in your namespace due to token injection For non-DevSpaces users: oc login --token= --server= oc project devspaces-userX <pre><code>oc create -f pod.yaml\n</code></pre> <li> <p>Add Service and Route:</p> <p>Expose the application by creating a service and route: <pre><code>oc create -f service.yaml\noc create -f route.yaml\n</code></pre> 3. Access the Application:</p> <p>Get the route URL and access your application: <pre><code>oc get route python-server-route -o jsonpath='{.spec.host}'\n\ncurl http://$(oc get route python-server-route -o jsonpath='{.spec.host}')\n</code></pre> You can also open the route URL in your web browser to view the application.</p> <p>You can find the route URL under \"Networking\" \u2192 \"Routes\" and click it to access your application.</p> </li> <li> <p>Note on Pod Deletion:</p> <p>Be aware that deleting the pod will result in the loss of the running instance.</p> </li>"},{"location":"tutorials/python/#exercises","title":"Exercises","text":""},{"location":"tutorials/python/#exercise-1-create-a-deployment-in-openshift","title":"Exercise 1: Create a Deployment in OpenShift","text":"<p>Objective: Learn how to create a deployment in OpenShift to manage your application.</p> <ol> <li> <p>Create a Deployment:</p> <p>Use the following command to create a deployment for your application:   <pre><code>oc create deployment python-server --image=registry.redhat.io/ubi9/python-312 -- python3 -m http.server\n</code></pre></p> </li> <li> <p>Verify the Deployment:</p> <p>Check the status of the deployment to ensure it was created successfully:   <pre><code>oc get deployments\n</code></pre></p> </li> <li> <p>Check the Pods:</p> <p>Verify that pods are running as part of the deployment:</p> <p>The pod name will have a random suffix appended to it, like: python-server-5b7f8d9c7b-xyz12 </p> <pre><code>oc get pods\n</code></pre> </li> </ol>"},{"location":"tutorials/python/#exercise-2-scale-the-deployment","title":"Exercise 2: Scale the Deployment","text":"<p>Objective: Understand how to scale a deployment to handle more traffic.</p> <ol> <li> <p>Scale the Deployment:</p> <p>Increase the number of replicas to handle more traffic:   <pre><code>oc scale --replicas=3 deploy/python-server\n</code></pre></p> </li> <li> <p>Verify Scaling:</p> <p>Check the status of the pods to ensure scaling was successful:   <pre><code>oc get pods\n</code></pre></p> </li> <li> <p>Test the Application:</p> <p>Ensure the application is still accessible and functioning correctly:   <pre><code>curl http://$(oc get route python-server-route -o jsonpath='{.spec.host}')\n</code></pre></p> </li> </ol>"},{"location":"tutorials/python/#exercise-3-update-the-deployment-with-a-new-image","title":"Exercise 3: Update the Deployment with a New Image","text":"<p>Objective: Learn how to update a deployment with a new version of your application.</p> <ol> <li> <p>Build a New Image:</p> <p>Make changes to your application and build a new image:   <pre><code>podman build -t python-server:v2 .\n</code></pre></p> </li> <li> <p>Import the Local Image to OpenShift:</p> <p>For Laptop Users:</p> <p>Note: The OpenShift internal registry has been exposed just for the workshop. </p> <p>Use the following command to log in to the OpenShift internal registry:   <pre><code>podman login -u $(oc whoami) -p $(oc whoami -t) https://default-route-openshift-image-registry.apps.cluster-2jp75.2jp75.sandbox2851.opentlc.com\n</code></pre>   Tag your local image with the OpenShift registry namespace:   <pre><code>podman tag python-server:v2 default-route-openshift-image-registry.apps.cluster-2jp75.2jp75.sandbox2851.opentlc.com/devspaces-user1/python-server:v2\n</code></pre>   Push the tagged image to the OpenShift internal registry:   <pre><code>podman push default-route-openshift-image-registry.apps.cluster-2jp75.2jp75.sandbox2851.opentlc.com/devspaces-user1/python-server:v2\n</code></pre></p> </li> </ol> <p>For DevSpaces Users:</p> <pre><code>  Use the following command to log in to the OpenShift internal registry:\n  ```bash\n  podman login -u $(oc whoami) -p $(oc whoami -t) image-registry.openshift-image-registry.svc:5000\n  ```\n  Tag your local image with the OpenShift registry namespace:\n  ```bash\n  podman tag python-server:v2 image-registry.openshift-image-registry.svc:5000/devspaces-user1/python-server:v2\n  ```\n  Push the tagged image to the OpenShift internal registry:\n  ```bash\n  podman push image-registry.openshift-image-registry.svc:5000/devspaces-user1/python-server:v2\n  ```\n</code></pre> <ol> <li> <p>Update the Deployment:</p> <p>Update the deployment to use the new image:   <pre><code>oc set image deployment/python-server python-312=python-server:v2 --source=imagestreamtag\n</code></pre></p> <p>An imagestream tag in OpenShift is a reference to a specific version of an image within an imagestream.</p> <p>It allows you to manage and track different versions of container images, facilitating seamless updates and rollbacks.</p> </li> <li> <p>Verify the Update:</p> </li> <li> <p>Check the status of the deployment to ensure it updated successfully:      <pre><code>oc rollout status deployment/python-server\n</code></pre></p> </li> <li> <p>Test the Updated Application:</p> </li> <li>Verify that the updated application is running correctly:      <pre><code>curl http://$(oc get route python-server-route -o jsonpath='{.spec.host}')\n</code></pre></li> </ol>"},{"location":"tutorials/rbac/","title":"RBAC (Role-Based Access Control)","text":""},{"location":"tutorials/rbac/#tutorials","title":"Tutorials","text":"<p>This demonstrates how to set up and test role-based access control in OpenShift.</p> <p>The code examples and instructions in this tutorial are located under <code>openshift-quickstart</code> project in the <code>tutorials/rbac</code> directory. </p> <p>Ensure you are in this directory before executing the commands. </p> <ol> <li> <p>Navigate to the Tutorial Directory     <pre><code># Change to the tutorials/simple directory\ncd openshift-quickstart/tutorials/rbac\n</code></pre></p> </li> <li> <p>Or open a New Terminal</p> </li> </ol>"},{"location":"tutorials/rbac/#steps","title":"Steps","text":"<ol> <li> <p>As an admin user of your namespaces, create a role that allows reading pod information:    <pre><code>oc create -f pod-reader.yaml\n</code></pre></p> </li> <li> <p>Create a RoleBinding to assign the pod-reader role to your user friend userX:    <pre><code># Replace userX with the target user and namespaceX with your namespace in the pod-reader-binding.\nsed -i 's/namespaceX/&lt;your-namespace&gt;/g' pod-reader-binding.yaml\nsed -i 's/userX/user2/g' pod-reader-binding.yaml\noc create -f pod-reader-binding.yaml\n</code></pre></p> </li> <li> <p>Ask your friend as userX and verify that you can:</p> </li> <li>View pods (<code>oc get pods</code>)</li> <li> <p>Cannot access other resources (services, routes, etc.)</p> </li> <li> <p>Add the standard view role to allow broader access:    <pre><code>oc adm policy add-role-to-user view userX -n &lt;your-namespace&gt;\n</code></pre></p> </li> <li> <p>Login as userX again and confirm that you can now:</p> </li> <li>View all basic resources in the namespace</li> <li>View pods, services, routes, configmaps, etc (no secrets).</li> <li>Cannot modify any resources (read-only access)</li> </ol>"},{"location":"tutorials/rbac/#exercises","title":"Exercises","text":""},{"location":"tutorials/rbac/#exercise-1-modify-an-existing-role","title":"Exercise 1: Modify an Existing Role","text":"<p>Objective: Learn how to modify an existing role to add or remove permissions.</p> <ol> <li> <p>Open the <code>pod-reader.yaml</code> file and add permissions to list services:      <pre><code>kind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  namespace: namespaceX\n  name: pod-reader\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"\"]\n  resources: [\"services\"]\n  verbs: [\"list\"]\n</code></pre></p> </li> <li> <p>Apply the changes to update the role:    <pre><code>  oc apply -f pod-reader.yaml\n</code></pre></p> </li> <li> <p>Check the updated role to ensure the changes were applied:    <pre><code>oc get role pod-reader -o yaml\n</code></pre></p> </li> <li> <p>Verify that you user friend can now list services in addition to viewing pods:     <pre><code>oc get services\noc get pods\n</code></pre>    Ensure that you cannot modify any resources:    <pre><code># Attempting to delete a pod should fail\noc delete pod &lt;pod-name&gt;\n</code></pre>    Confirm that you still cannot access other resources like secrets:    <pre><code>oc get secrets\n</code></pre></p> </li> </ol>"},{"location":"tutorials/rbac/#exercise-2-create-a-service-account","title":"Exercise 2: Create a Service Account","text":"<p>Objective: Learn how to create a service account and bind a role to it within your own namespace.</p> <p>Note: A service account in Kubernetes is an identity that processes within a pod can use to interact with the Kubernetes API. It provides a way to control access to resources within a namespace, allowing for more granular permission management compared to using user accounts. Service accounts are particularly useful for applications running within the cluster that need to interact with the Kubernetes API.</p> <ol> <li> <p>Use the following command to create a service account named <code>pod-viewer</code> in your namespace:     <pre><code>oc create serviceaccount pod-viewer -n namespaceX\n</code></pre></p> </li> <li> <p>Create a YAML file named <code>sa-rolebinding.yaml</code> to bind the <code>view</code> role to the <code>pod-viewer</code> service account:     &gt; Note: Ensure to replace <code>namespaceX</code> with your actual namespace where you want the service account and role binding to be applied.</p> <pre><code>kind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: sa-view-binding\n  namespace: namespaceX\nsubjects:\n- kind: ServiceAccount\n  name: pod-viewer\n  namespace: namespaceX\nroleRef:\n  kind: Role\n  name: view\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> </li> <li> <p>Use the following command to create the role binding for the service account:      <pre><code>oc create -f sa-rolebinding.yaml\n</code></pre></p> </li> <li> <p>Check that the service account and role binding have been created:      <pre><code>oc get serviceaccounts\noc get rolebindings\n</code></pre></p> </li> <li> <p>Use the service account to verify that it can view and list pods in the <code>namespaceX</code> namespace:      <pre><code>oc auth can-i get pods --as=system:serviceaccount:namespaceX:pod-viewer -n namespaceX\n</code></pre>    Ensure that the service account cannot modify resources:      <pre><code># Attempting to delete a pod should fail\noc auth can-i delete pod --as=system:serviceaccount:namespaceX:pod-viewer -n namespaceX\n</code></pre></p> </li> </ol>"},{"location":"tutorials/simple/","title":"Simple Container","text":""},{"location":"tutorials/simple/#tutorial","title":"Tutorial","text":"<p>This guide walks through basic container operations using Podman.</p> <p>The code examples and instructions in this tutorial are located under <code>openshift-quickstart</code> project in the <code>tutorials/simple</code> directory. </p> <p>Ensure you are in this directory before executing the commands. </p> <ol> <li> <p>Navigate to the Tutorial Directory     <pre><code>cd openshift-quickstart/tutorials/simple\n</code></pre></p> </li> <li> <p>Or open a New Terminal   </p> </li> <li> <p>Build an image tagged as 'simple:latest' from the Dockerfile in current directory     <pre><code>podman build -t simple:latest .\n</code></pre></p> </li> <li> <p>Run the container in detached mode     <pre><code>podman run -d simple:latest\n</code></pre></p> </li> <li> <p>List all running containers     <pre><code>podman ps -a\n</code></pre></p> </li> <li> <p>Start a new container with an interactive bash shell     <pre><code>podman run -it --entrypoint /bin/bash simple:latest\n</code></pre></p> </li> <li> <p>View Container Logs, split the terminal     <pre><code># First get the container ID\npodman ps\n\n# Stream the logs from the container (-f follows the log output)\npodman logs -f &lt;containerID&gt;\n</code></pre></p> <p></p> <p>Replace <code>&lt;containerID&gt;</code> with the actual container ID </p> <p>from <code>podman ps</code> output or <code>$(podman ps -q)</code>. </p> </li> </ol>"},{"location":"tutorials/simple/#exercies","title":"Exercies","text":""},{"location":"tutorials/simple/#exercise-1-modify-and-rebuild-the-container-image","title":"Exercise 1: Modify and Rebuild the Container Image","text":"<p>Objective: Learn how to modify a <code>Containerfile</code> and rebuild the container image.</p> <ol> <li> <p>Edit the <code>Containerfile</code>:</p> <p>Open the <code>Containerfile</code> in a text editor.</p> <p>Add a new environment variable to the image. For example, add the line: <pre><code>ENV MY_VAR=\"Hello, Podman!\"\n</code></pre></p> </li> <li> <p>Rebuild the Container Image:</p> <p>Use the following command to rebuild the image with the new changes: <pre><code>podman build -t simple:latest .\n</code></pre></p> </li> <li> <p>Verify the Changes:</p> <p>Run a new container and check if the environment variable is set: <pre><code>podman run --rm --entrypoint printenv simple:latest MY_VAR\n</code></pre></p> <p>The <code>--entrypoint</code> flag overrides the default <code>echo</code> command defined in the Containerfile, </p> <p>allowing us to run the <code>printenv</code> command instead to verify our environment variable.</p> </li> </ol>"},{"location":"tutorials/simple/#exercise-2-create-and-use-a-volume","title":"Exercise 2: Create and Use a Volume","text":"<p>Objective: Understand how to create and use volumes to persist data.</p> <ol> <li> <p>Create a Volume:</p> <p>Create a new volume named <code>mydata</code>: <pre><code>podman volume create mydata\n</code></pre></p> </li> <li> <p>Run a Container with the Volume:</p> <p>Start a container and mount the volume to <code>/data</code> inside the container: <pre><code>podman run -it -d -v mydata:/data --entrypoint cat simple:latest\n</code></pre></p> <p>The <code>-it</code> flags enable an interactive terminal session. </p> <p>We use <code>cat</code> as the entrypoint to keep the container running in detached mode (<code>-d</code>), since <code>cat</code> will wait for input indefinitely.</p> </li> <li> <p>Verify the Volume:</p> <p>Access the container and create a file in the <code>/data</code> directory: <pre><code>podman ps\npodman exec -it &lt;containerID&gt; touch /data/hello.txt\n</code></pre></p> </li> <li> <p>Check the Volume Content:</p> <p>Verify the file exists in the volume: <pre><code>podman run -it -v mydata:/data --entrypoint /bin/bash simple:latest\n[root@283f981a19f2 /]# ls /data\nhello.txt\n</code></pre></p> </li> </ol>"},{"location":"tutorials/simple/#exercise-3-inspect-and-manage-container-logs","title":"Exercise 3: Inspect and Manage Container Logs","text":"<p>Objective: Learn how to inspect and manage logs from a running container.</p> <ol> <li> <p>Run a Container:     Start a container that outputs logs:     <pre><code>podman run -d --entrypoint /bin/sh simple:latest -c \"while true; do echo 'Hello from container'; sleep 5; done\"\n</code></pre></p> </li> <li> <p>View Logs:</p> <p>Use the following command to stream logs from the container: <pre><code>podman logs -f &lt;containerID&gt;\n</code></pre></p> </li> <li> <p>Stop the Container:</p> <p>Stop the container after observing the logs: <pre><code>podman stop &lt;containerID&gt;\n</code></pre></p> </li> </ol>"}]}